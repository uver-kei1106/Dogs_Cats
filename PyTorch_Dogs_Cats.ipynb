{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms,models\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"CPU\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR=\"../input/dogs-and-cats-datasets/train/train\"\nTEST_DIR=\"../input/dogs-and-cats-datasets/test/test\"\nfile_list_train=os.listdir(TRAIN_DIR)\n_file_list_test=os.listdir(TEST_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_file_list_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install natsort","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from natsort import natsorted\nfile_list_test=[]\nfor path in natsorted(_file_list_test):\n    file_list_test.append(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_list_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROWS=64\nCOLS=64\nCHANNELS=3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_files=[file_name for file_name in file_list_train if \"cat\" in file_name]\ndog_files=[file_name for file_name in file_list_train if \"dog\" in file_name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(cat_files))\nprint(len(dog_files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_cat_files, val_cat_files = train_test_split(cat_files, test_size=0.2)\ntrain_dog_files, val_dog_files = train_test_split(dog_files, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform=transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\n\nval_transform=transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\n\ntest_transform=transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CatDogDataset(Dataset):\n    def __init__(self,file_list,dir,transform=None):\n        self.file_list=file_list\n        self.dir=dir\n        self.transform=transform\n        if \"dog\" in self.file_list[0]:\n            self.label=1\n        else:\n            self.label=0\n    def __len__(self):\n        return len(self.file_list)\n    def __getitem__(self,idx):\n        file_path =os.path.join(self.dir,self.file_list[idx])\n        img=Image.open(file_path)\n        if self.transform is not None:\n            img =self.transform(img)\n        return img,self.label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_path=\"../input/dogs-and-cats-datasets/train/train\"\ntrain_cat_dataset=CatDogDataset(train_cat_files,dir_path,transform=train_transform)\ntrain_dog_dataset=CatDogDataset(train_dog_files,dir_path,transform=train_transform)\nval_cat_dataset=CatDogDataset(val_cat_files,dir_path,transform=val_transform)\nval_dog_dataset=CatDogDataset(val_dog_files,dir_path,transform=val_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_cat_dataset))\nprint(len(train_dog_dataset))\nprint(len(val_cat_dataset))\nprint(len(val_dog_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat_dataset.file_list=train_cat_dataset.file_list[:100]\ntrain_dog_dataset.file_list=train_dog_dataset.file_list[:100]\nval_cat_dataset.file_list=val_cat_dataset.file_list[:10]\nval_dog_dataset.file_list=val_dog_dataset.file_list[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat_dog_dataset=ConcatDataset([train_cat_dataset,train_dog_dataset])\nval_cat_dog_dataset=ConcatDataset([val_cat_dataset,val_dog_dataset])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_samples = len(train_cat_dog_dataset) \ntrain_size = int(n_samples * 0.8)\nsubset1_indices = list(range(0,train_size))\nsubset2_indices = list(range(train_size,n_samples))\nfrom torch.utils.data.dataset import Subset\ntrain_dataset = Subset(train_cat_dog_dataset, subset1_indices)\nval_dataset   = Subset(train_cat_dog_dataset, subset2_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader=DataLoader(train_cat_dog_dataset,batch_size=32,shuffle=True)\nvalidation_dataloader=DataLoader(val_cat_dog_dataset,batch_size=32,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_iter=iter(train_dataloader)\nimgs,labels=data_iter.next()\nimg=imgs[0]\nimg_prmute=img.permute(1,2,0)\nimg_permute=0.5*img_prmute+0.5\nimg_permute=np.clip(img_permute,0,1)\nplt.imshow(img_permute)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self,num_classes):\n        super().__init__()\n        self.features=nn.Sequential(\n            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=5,padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=256,out_channels=128,kernel_size=3,padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.classifier=nn.Linear(in_features=32*32*128,out_features=num_classes)\n    def forward(self,x):\n        x=self.features(x)\n        x=x.view(x.size(0),-1)\n        x=self.classifier(x)\n        #x=nn.ReLU(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=models.vgg16(pretrained=True)\n#model=models.resnet18(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.classifier[6] = nn.Linear(in_features=4096, out_features=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_to_update = []\n\nupdate_params_name = ['classifier.6.weight', 'classifier.6.bias']\n\nfor name, param in model.named_parameters():\n    if name in update_params_name:\n        param.requires_grad = True\n        params_to_update.append(param)\n        print(name)\n    else:\n        param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model=CNN(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion=nn.CrossEntropyLoss()\noptimizer=optim.SGD(params=params_to_update,lr=0.001,momentum=0.9)\n#optimizer=optim.Adam(model.parameters(),lr=0.001,weight_decay=5e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs=5\nlosses=[]\naccs=[]\nval_losses=[]\nval_accs=[]\nfor epoch in range(num_epochs):\n    running_loss=0.0\n    running_acc=0.0\n    for imgs,labels in train_dataloader:\n        imgs=imgs.to(device)\n        labels=labels.to(device)\n        optimizer.zero_grad()\n        output=model(imgs)\n        loss=criterion(output,labels)\n        loss.backward()\n        running_loss+=loss.item()\n        pred=torch.argmax(output,dim=1)\n        #print(pred)\n        running_acc+=torch.mean(pred.eq(labels).float())\n        optimizer.step()\n    running_loss /=len(train_dataloader)\n    running_acc /=len(train_dataloader)\n    losses.append(running_loss)\n    accs.append(running_acc)\n\n    val_running_loss=0.0\n    val_running_acc=0.0\n    for val_imgs,val_labels in validation_dataloader:\n        val_imgs=val_imgs.to(device)\n        val_labels=val_labels.to(device)\n        val_output=model(val_imgs)\n        val_loss=criterion(val_output,val_labels)\n        val_running_loss+= val_loss.item()\n        val_pred=torch.argmax(val_output,dim=1)\n        val_running_acc+=torch.mean(val_pred.eq(val_labels).float())\n    val_running_loss/=len(validation_dataloader)\n    val_running_acc/=len(validation_dataloader)\n    val_losses.append(val_running_loss)\n    val_accs.append(val_running_acc)\n    print(\"epoch:{},        loss:{},        acc:{},     val loss:{},        val acc:{}\".format(epoch,running_loss,running_acc,val_running_loss,val_running_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\nplt.plot(losses,label=\"train loss\")\nplt.plot(val_losses,label=\"validation loss\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.plot(accs,label=\"train acc\")\nplt.plot(val_accs,label=\"validation acc\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* この下からtestの検証"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_files=[file_name for file_name in file_list_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_path=\"../input/dogs-and-cats-datasets/test/test\"\ntest_dataset=CatDogDataset(test_files,dir_path,transform=test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataloader=DataLoader(test_dataset,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndata_iter=list(iter(test_dataloader))\nimgs,labels=data_iter[0]\nimg=imgs[0]\nimg_prmute=img.permute(1,2,0)\nimg_permute=0.5*img_prmute+0.5\nimg_permute=np.clip(img_permute,0,1)\nplt.imshow(img_permute)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=[]\nfor imgs,labels in test_dataloader:\n    imgs=imgs.to(device)\n    output=model(imgs)\n    #pred=torch.argmax(output,dim=1)\n    pred= F.softmax(output, dim=1)[:, 1]\n    pred2 = pred.to('cpu').detach().numpy().copy()\n    result.append(pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(output)\nprint(pred)\nprint(pred2)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2=np.array(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result3 = result2.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result4=result3.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsubmission=pd.DataFrame({\"label\":result4})\nsubmission.index = submission.index + 1\nsubmission.to_csv((\"./submission_4.csv\"),index_label=[\"id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}